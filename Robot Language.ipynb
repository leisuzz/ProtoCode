{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329f15f3",
   "metadata": {},
   "source": [
    "# Robot Language Conversion\n",
    "script leverages fine-tuned model to obtain the standardized protocols, and converts to robot language\n",
    "   \n",
    "## input files\n",
    "- **config file** \n",
    "\n",
    "    - In cofig file, please specify the following four items:\n",
    "\n",
    "        - **input_file** : saved protocols from paper extraction \n",
    "        - **input_content** : mannually script content if the extraction didn't work \n",
    "        - **model_selection** : select model among five fine-tuned models from five-fold cross-validation \n",
    "        - **output_path** : save the converted robot language file\n",
    "        \n",
    "## output files\n",
    "\n",
    "The obtained protocols are stored in the **\"./output_language/\"** folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a01516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import ast\n",
    "import spacy\n",
    "import configparser\n",
    "import errno\n",
    "import logging\n",
    "\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5fc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./robot_language_config.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b4b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_reformat(input_path):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Initialize variables to track the current article\n",
    "    current_article = ''\n",
    "    protocols = []\n",
    "    i = None\n",
    "    \n",
    "    # Iterate through the DataFrame and combine headings and content when 'protocol index' is 0\n",
    "    for index, row in df.iterrows():\n",
    "        protocol_index = row['protocol index']\n",
    "        heading = row['heading name']\n",
    "        content = row['content']\n",
    "\n",
    "        # Check if the protocol index is equal to i\n",
    "        if protocol_index == i or i is None:\n",
    "            # Concatenate heading and content into the current article\n",
    "            current_article += f\"{heading}\\n{content}\\n\"\n",
    "        else:\n",
    "            # Save the current article to protocols\n",
    "            protocols.append(current_article)\n",
    "\n",
    "            # Start a new current article with the current row\n",
    "            current_article = f\"{heading}\\n{content}\\n\"\n",
    "\n",
    "        # Update the current protocol index\n",
    "        i = protocol_index\n",
    "    \n",
    "    # Append the last article\n",
    "    if current_article:\n",
    "        protocols.append(current_article)\n",
    "    \n",
    "    return protocols\n",
    "\n",
    "def gpt_extraction(content, openai_api_key, Model):\n",
    "    \n",
    "    openai.api_key = openai_api_key\n",
    "    # input content\n",
    "    completion = openai.ChatCompletion.create(\n",
    "              model=Model,\n",
    "              temperature = 0,\n",
    "              messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a biomedical expert\"},\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "              ],\n",
    "            )\n",
    "    # obtain result\n",
    "    output_message = completion.choices[0].message['content']\n",
    "    return output_message\n",
    "\n",
    "def extract_PCR(text):\n",
    "    \n",
    "    content = []\n",
    "    result_content = ast.literal_eval(text)\n",
    "\n",
    "    # find # of PCR\n",
    "    if len(result_content)==2:\n",
    "        rc = ['First PCR', 'Second PCR']\n",
    "        for i in rc:\n",
    "            reagents = result_content[i]['Thermal cycling condition'][0]\n",
    "            # Iterate through the reagent components and write the data to the CSV\n",
    "            cycle = reagents.get('Program')\n",
    "            detail = reagents.get('Thermal cycler', [{}])[0]\n",
    "            machine = detail.get('PCRmachine')\n",
    "            content.append(cycle)\n",
    "    else:\n",
    "        reagents = result_content['Thermal cycling condition'][0]\n",
    "\n",
    "        # Iterate through the reagent components and write the data to the CSV\n",
    "        cycle = reagents.get('Program')\n",
    "        content.append(cycle)\n",
    "        detail = reagents.get('Thermal cycler', [{}])[0]\n",
    "        machine = detail.get('PCRmachine')\n",
    "        \n",
    "    return content, machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7583b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_clauses(text):\n",
    "    split_pattern1 = re.compile(r'[;]\\s*')\n",
    "    split_pattern2 = re.compile(r'(?<!\\d)[.](?!\\d)\\s*')\n",
    "    split_pattern3 = re.compile(r'[,](?!\\s+\\d|\\s+followed|\\s+and)')\n",
    "\n",
    "    # Split the text into sentences using the custom pattern\n",
    "    sentences1 = split_pattern1.split(text)\n",
    "\n",
    "    sentences2 = []\n",
    "    sentences3 = []\n",
    "    for sentence in sentences1:\n",
    "        sub_sentences = split_pattern2.split(sentence)\n",
    "        sentences2.extend(sub_sentences)\n",
    "        \n",
    "    for sentence in sentences2:\n",
    "        sub_sentences = split_pattern3.split(sentence)\n",
    "        sentences3.extend(sub_sentences)\n",
    "\n",
    "    return sentences3\n",
    "\n",
    "def extract_temp_dura_details(content):\n",
    "#     temperature_pattern = r'(\\d+\\s*°\\s*C)'\n",
    "    temperature_pattern = r'(\\d+(?:\\.\\d+)?\\s*°\\s*C)'\n",
    "    duration_pattern = r'(\\d+\\s*(?:s|S|min|Min|MIN|Seconds|seconds|minutes|Minutes))'\n",
    "    \n",
    "    temp_dutn = re.findall(temperature_pattern + r'\\s*.*?' + duration_pattern, content, re.I)\n",
    "    if not temp_dutn:\n",
    "        matches = re.findall(duration_pattern + r'\\s*.*?' + temperature_pattern, content, re.I)\n",
    "        temp_dutn = []\n",
    "        for match in matches:\n",
    "            temp_dutn.append((match[1], match[0]))\n",
    "            \n",
    "    return temp_dutn\n",
    "\n",
    "def extract_cycle(content):\n",
    "    # Extract number of cycles\n",
    "    cycles = re.findall(r'(\\d+\\s*cycles)|(\\w+\\s*cycles)', content, re.I)\n",
    "    return cycles\n",
    "\n",
    "def allcycle(content, cycles):\n",
    "    cyc_file = None\n",
    "    # Add fixed sections\n",
    "    fixed_sections = (\n",
    "            \"[Properties]\\nName=\\nComment=\\nDWS-ability=0x00000015\\n\\n\",\n",
    "            \"[EstTime]\\nDuration=00:00:00\\n\\n\",\n",
    "            \"[000]\\nOpcode=HEADER\\nLidTemp=105.0∞C\\nWait=YES\\nLowBlock=AUTO\\nEmuMode=FULL\\nTempMode=STANDARD\\nControl=SIM_TUBE\\nImpuls=NO\\nBlocktype=ANY\\nSlope=STEADY\\nLidTrack=NO\\n\"\n",
    "        )\n",
    "    cyc_file = fixed_sections[0] + fixed_sections[1] + fixed_sections[2]\n",
    "    \n",
    "    temp_file = \"\"  # temporary file to store steps in cycles\n",
    "    \n",
    "    order_num = 1\n",
    "    temp_num = 1\n",
    "    for sentence in content:\n",
    "        # extract temperature and duration\n",
    "        temp_dutn = extract_temp_dura_details(sentence)\n",
    "        \n",
    "        # extract number of temperature and duration for cycles\n",
    "        tempNum = len(temp_dutn)\n",
    "\n",
    "        # set initial seconds and minutes\n",
    "        minutes = 0\n",
    "        seconds = 0\n",
    "        \n",
    "        # Define a regular expression pattern to match 'room temperature' case-insensitively\n",
    "        pattern = re.compile(r'room temperature', re.IGNORECASE)\n",
    "\n",
    "        # Search for the pattern in the sentence\n",
    "        match = pattern.search(sentence)\n",
    "        \n",
    "        if match:\n",
    "             for i in temp_dutn:\n",
    "                minutes = '00'\n",
    "                seconds = '00'\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "\n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                cyc_file += f\"\\n[00{order_num}]\\nOpcode=TEMP\\nTemp={temp_number}∞C {temp_number}∞C {minutes}:{seconds} R=100%\\n\"\n",
    "                order_num += 1\n",
    "        else:\n",
    "            for i in temp_dutn:\n",
    "                minutes = '00'\n",
    "                seconds = '00'\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "\n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                temp_file += f\"Temp{temp_num}={temp_number}∞C {temp_number}∞C {minutes}:{seconds} +0.0∞C +00:00 R=100%\\n\"\n",
    "                temp_num += 1\n",
    "            \n",
    "    cyc_file += f\"\\n[00{order_num}]\\nOpcode=CYCLE\\nTempNum={temp_num-1}\\nCycles={cycles}\\n\"\n",
    "    cyc_file += temp_file\n",
    "    order_num += 1\n",
    "    cyc_file += f\"\\n[00{order_num}]\\nOpcode=END\\n\\n[~CRC32~]\\ncrc=0x1D14D6F3\"\n",
    "    return cyc_file\n",
    "\n",
    "def Biorad_allcycle(content, cycles):\n",
    "    cyc_file = \"[ProtocolRunDefinition version 06.00]METHOD CALC;HOTLID 105,30;VOLUME 40;\"\n",
    "    allcycle_file = None\n",
    "    \n",
    "    temp_file = \"\"  # temporary file to store steps in cycles\n",
    "    \n",
    "    order_num = 1\n",
    "    temp_num = 1\n",
    "    for sentence in content:\n",
    "        # extract temperature and duration\n",
    "        temp_dutn = extract_temp_dura_details(sentence)\n",
    "        \n",
    "        # extract number of temperature and duration for cycles\n",
    "        tempNum = len(temp_dutn)\n",
    "\n",
    "        # set initial seconds and minutes\n",
    "        minutes = 0\n",
    "        seconds = 0\n",
    "        times = 0\n",
    "        # Define a regular expression pattern to match 'room temperature' case-insensitively\n",
    "        pattern = re.compile(r'room temperature', re.IGNORECASE)\n",
    "\n",
    "        # Search for the pattern in the sentence\n",
    "        match = pattern.search(sentence)\n",
    "        \n",
    "        if match:\n",
    "            for i in temp_dutn:\n",
    "                times = 0\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "                \n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                    times += int(minutes.text) * 60\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                    times += int(seconds.text)\n",
    "                cyc_file += f\"TEMP {float(temp_number.text)},{times};\"\n",
    "                order_num += 1\n",
    "        else:\n",
    "            for i in temp_dutn:\n",
    "                times = 0\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "\n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                    times += int(minutes.text) * 60\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                    times += int(seconds.text)\n",
    "                temp_file += f\"TEMP {float(temp_number.text)},{times};\"\n",
    "                temp_num += 1\n",
    "            \n",
    "    cyc_file += temp_file\n",
    "    cyc_file += f\"GOTO {order_num},{cycles};\"\n",
    "    cyc_file += f\"END;\"\n",
    "    return cyc_file\n",
    "\n",
    "def convert_text_to_number(input_string):\n",
    "    words = input_string.split()\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            numeric_value = w2n.word_to_num(word)\n",
    "            words[i] = str(numeric_value)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "def Eppendorf_file(content, nlp, temp_dutn):\n",
    "    cyc_file = None\n",
    "    fixed_sections = (\n",
    "            \"[Properties]\\nName=\\nComment=\\nDWS-ability=0x00000015\\n\\n\",\n",
    "            \"[EstTime]\\nDuration=00:00:00\\n\\n\",\n",
    "            \"[000]\\nOpcode=HEADER\\nLidTemp=105.0∞C\\nWait=YES\\nLowBlock=AUTO\\nEmuMode=FULL\\nTempMode=STANDARD\\nControl=SIM_TUBE\\nImpuls=NO\\nBlocktype=ANY\\nSlope=STEADY\\nLidTrack=NO\\n\"\n",
    "        )\n",
    "    cyc_file = fixed_sections[0] + fixed_sections[1] + fixed_sections[2]\n",
    "    allcycle_file = None\n",
    "\n",
    "    order_num = 1\n",
    "    cycles = None\n",
    "\n",
    "    for sentence in content:\n",
    "        # extract temperature and duration\n",
    "        temp_dutn = extract_temp_dura_details(sentence)\n",
    "\n",
    "        # extract number of temperature and duration for cycles\n",
    "        tempNum = len(temp_dutn)\n",
    "\n",
    "        # set initial seconds and minutes\n",
    "        minutes = 0\n",
    "        seconds = 0\n",
    "\n",
    "        if extract_cycle(sentence):\n",
    "            cycles_match = re.search(r'(\\d+\\s*cycles)|(\\w+\\s*cycles)', sentence, re.I)\n",
    "            match = nlp(cycles_match.group())\n",
    "\n",
    "            # find number of cycles\n",
    "            for word in match:\n",
    "                try:\n",
    "                    num_cycles = w2n.word_to_num(str(word))\n",
    "                    cycles = num_cycles\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if tempNum == 0:\n",
    "                allcycle_file = allcycle(content, cycles)\n",
    "                break\n",
    "            else:\n",
    "                cyc_file += f\"\\n[00{order_num}]\\nOpcode=CYCLE\\nTempNum={tempNum}\\nCycles={cycles}\\n\"\n",
    "                # if didn't mention how many cycles, will be all in cycles\n",
    "                for i in range(len(temp_dutn)):\n",
    "                    minutes = '00'\n",
    "                    seconds = '00'\n",
    "                    temp = nlp(temp_dutn[i][0])\n",
    "                    temp_number = temp[0]\n",
    "                    dur = temp_dutn[i][1]\n",
    "\n",
    "                    # find minutes and seconds\n",
    "                    if 'm' in dur:\n",
    "                        d = nlp(dur)\n",
    "                        minutes = d[0]\n",
    "                    else:\n",
    "                        d = nlp(dur)\n",
    "                        seconds = d[0]\n",
    "                    cyc_file += f\"Temp{i+1}={temp_number}∞C {temp_number}∞C {minutes}:{seconds} +0.0∞C +00:00 R=100%\\n\"\n",
    "            order_num += 1\n",
    "        else:\n",
    "            for i in temp_dutn:\n",
    "                minutes = '00'\n",
    "                seconds = '00'\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "\n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                cyc_file += f\"\\n[00{order_num}]\\nOpcode=TEMP\\nTemp={temp_number}∞C {temp_number}∞C {minutes}:{seconds} R=100%\\n\"\n",
    "                order_num += 1\n",
    "\n",
    "    cyc_file += f\"\\n[00{order_num}]\\nOpcode=END\\n\\n[~CRC32~]\\ncrc=0x1D14D6F3\"\n",
    "    return cyc_file, allcycle_file\n",
    "\n",
    "def Biorad_file(content, nlp, temp_dutn):\n",
    "    cyc_file = \"[ProtocolRunDefinition version 06.00]METHOD CALC;HOTLID 105,30;VOLUME 40;\"\n",
    "    allcycle_file = None\n",
    "    order_num = 1\n",
    "    cycles = None\n",
    "\n",
    "    for sentence in content:\n",
    "        # extract temperature and duration\n",
    "        temp_dutn = extract_temp_dura_details(sentence)\n",
    "        # extract number of temperature and duration for cycles\n",
    "        tempNum = len(temp_dutn)\n",
    "        \n",
    "        # set initial seconds and minutes\n",
    "        minutes = 0\n",
    "        seconds = 0\n",
    "        times = 0\n",
    "\n",
    "        if extract_cycle(sentence):\n",
    "            cycles_match = re.search(r'(\\d+\\s*cycles)|(\\w+\\s*cycles)', sentence, re.I)\n",
    "            match = nlp(cycles_match.group())\n",
    "\n",
    "            # find number of cycles\n",
    "            for word in match:\n",
    "                try:\n",
    "                    num_cycles = w2n.word_to_num(str(word))\n",
    "                    cycles = num_cycles\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # if sentence only mention cycles without temperature and duration, it will be all cycles\n",
    "            if tempNum == 0:\n",
    "                allcycle_file = Biorad_allcycle(content, cycles)\n",
    "                break\n",
    "            else:\n",
    "                cyc_num = order_num\n",
    "                for i in range(len(temp_dutn)):\n",
    "                    temp = nlp(temp_dutn[i][0])\n",
    "                    temp_number = temp[0]\n",
    "                    dur = temp_dutn[i][1]\n",
    "                    times = 0\n",
    "                    \n",
    "                    # find minutes and seconds\n",
    "                    if 'm' in dur:\n",
    "                        d = nlp(dur)\n",
    "                        minutes = d[0]\n",
    "                        times += int(minutes.text) * 60\n",
    "                    else:\n",
    "                        d = nlp(dur)\n",
    "                        seconds = d[0]\n",
    "                        times += int(seconds.text)\n",
    "                    cyc_file += f\"TEMP {float(temp_number.text)},{times};\"\n",
    "                cyc_file += f\"GOTO {cyc_num},{int(cycles)-1};\"\n",
    "            order_num += 1\n",
    "        else:\n",
    "            for i in temp_dutn:\n",
    "                times = 0\n",
    "                temp = nlp(i[0])\n",
    "                temp_number = temp[0]\n",
    "                dur = i[1]\n",
    "                # find minutes and seconds\n",
    "                if 'm' in dur:\n",
    "                    d = nlp(dur)\n",
    "                    minutes = d[0]\n",
    "                    times += int(minutes.text) * 60\n",
    "                else:\n",
    "                    d = nlp(dur)\n",
    "                    seconds = d[0]\n",
    "                    times += int(seconds.text)\n",
    "                cyc_file += f\"TEMP {float(temp_number.text)},{times};\"\n",
    "                order_num += 1\n",
    "\n",
    "    cyc_file += f\"END;\"\n",
    "    return cyc_file, allcycle_file\n",
    "\n",
    "def cyc_generator(content, results_save_path, openai_api_key, model, logger, i=None):\n",
    "    try:\n",
    "        # Load the English language model\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occured in loading spacy en_core_web_sm:{str(e)}\")\n",
    "        raise ValueError(f\"Error occured in loading spacy en_core_web_sm:{str(e)}\")\n",
    "  \n",
    "    try:\n",
    "        # Obtain protocol using fine-tuned model\n",
    "        gpt_content = gpt_extraction(content, openai_api_key, model)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occured in extraction from fine-tuned model:{str(e)}\")\n",
    "        raise ValueError(f\"Error occured in extraction from fine-tuned model:{str(e)}\")\n",
    "    try:\n",
    "        if i:\n",
    "            with open(f\"{results_save_path}gpt_out_{i}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(gpt_content)\n",
    "        else:\n",
    "            with open(f\"{results_save_path}gpt_out.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(gpt_content)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occured when save gpt output:{str(e)}\")\n",
    "        raise ValueError(f\"Error occured when save gpt output:{str(e)}\")\n",
    "        \n",
    "    try:\n",
    "        # Obtain thermal cycler part\n",
    "        pcr_content, _ = extract_PCR(gpt_content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error occured in extracting thermal cycler part:{str(e)}\")\n",
    "        raise ValueError(f\"Error occured in extracting thermal cycler part:{str(e)}\")\n",
    "        \n",
    "    for j in range(len(pcr_content)):\n",
    "        thermalcyc = []\n",
    "        try:\n",
    "            # split text for extraction\n",
    "            pcr = split_text_into_clauses(pcr_content[j])\n",
    "\n",
    "            # Convert text into number if it exist\n",
    "            for k in range(len(pcr)):\n",
    "                thermalcyc.append(convert_text_to_number(pcr[k]))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in split/convert text:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in split/convert text:{str(e)}\")\n",
    "\n",
    "        try:\n",
    "            # Extract temperature and duration time\n",
    "            temp_dutn = extract_temp_dura_details(str(thermalcyc))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in extract temperature and duration time:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in extract temperature and duration time:{str(e)}\")\n",
    "\n",
    "        try:\n",
    "            # Obtain CYC and TEMP section\n",
    "            cyc_file, allcyc = Eppendorf_file(thermalcyc, nlp, temp_dutn)\n",
    "            \n",
    "            path = f\"{results_save_path}Eppendorf_file_{i}_{j}.txt\"\n",
    "\n",
    "            if allcyc != None:\n",
    "                with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(allcyc)\n",
    "            else:\n",
    "                with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(cyc_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in obtain Eppendorf CYC and TEMP section:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in obtain Eppendorf CYC and TEMP section:{str(e)}\")\n",
    "        \n",
    "        try:\n",
    "            # Obtain CYC and TEMP section\n",
    "            biocyc_file, bioallcyc = Biorad_file(thermalcyc, nlp, temp_dutn)\n",
    "            \n",
    "            biopath = f\"{results_save_path}BioRad_file{i}_{j}.txt\"\n",
    "\n",
    "            if bioallcyc != None:\n",
    "                with open(biopath, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(bioallcyc)\n",
    "            else:\n",
    "                with open(biopath, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(biocyc_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in obtain BioRad CYC and TEMP section:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in obtain BioRad CYC and TEMP section:{str(e)}\")\n",
    "    return cyc_file, allcyc, biocyc_file, bioallcyc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9a1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_path, manu_content, results_save_path, openai_api_key, model, logger):\n",
    "    \n",
    "    # if use manual input\n",
    "    if manu_content:\n",
    "        try:\n",
    "            content = manu_content\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in loading custom content:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in loading custom content:{str(e)}\")\n",
    "            \n",
    "        cyc_file, allcyc, biocyc_file, bioallcyc = cyc_generator(content, results_save_path, openai_api_key, model, logger)\n",
    "        \n",
    "    else:   \n",
    "        try:\n",
    "            input_content = content_reformat(input_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occured in loading input content:{str(e)}\")\n",
    "            raise ValueError(f\"Error occured in loading input content:{str(e)}\")\n",
    "\n",
    "        for i in range(len(input_content)):\n",
    "            content = input_content[i]\n",
    "            cyc_file, allcyc, biocyc_file, bioallcyc = cyc_generator(content, results_save_path, openai_api_key, model, logger, i)\n",
    "    return cyc_file, allcyc, biocyc_file, bioallcyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f59f861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### read ini file\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), config_path)\n",
    "\n",
    "try:\n",
    "    config.read(config_path, encoding=\"utf-8\")\n",
    "\n",
    "    ## input link\n",
    "    input_path = config.get(\"input_file\", \"input_path\")\n",
    "    \n",
    "    ## input content\n",
    "    manu_content = config.get(\"input_content\", \"content\")\n",
    "    \n",
    "    ## model selection\n",
    "    model_num = config.getint(\"model_selection\", \"model_num\")\n",
    "    \n",
    "    ## output dir\n",
    "    results_save_path = config.get(\"output_path\", \"output_path\")\n",
    "    \n",
    "    ## openai key\n",
    "    openai_api_key = config.get(\"openai_key\", \"key\")\n",
    "    \n",
    "    ## fine-tuned models\n",
    "    models = config.get(\"finetuned_models\", \"models\")\n",
    "    \n",
    "    # Set the file path for the log file\n",
    "    log_file = \"./error.log\"\n",
    "\n",
    "    # Configure the logging settings\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create a FileHandler to save logs to the specified file path\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setLevel(logging.ERROR)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Create a formatter to customize the log message format\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    # Add the FileHandler to the logger\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Parse the string representation of the list into an actual list\n",
    "    models = ast.literal_eval(models)\n",
    "    \n",
    "    model = models[model_num-1]\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error occured in reading setting.ini:\", e)\n",
    "\n",
    "Eppendorf_file1, Eppendorf_file2, BioRad_file1, BioRad_file2 = main(input_path, manu_content, results_save_path, openai_api_key, model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf461b4-1d68-4504-ad81-7c74a2d4178b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
